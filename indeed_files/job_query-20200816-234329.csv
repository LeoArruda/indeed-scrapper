202008161	https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Bt274jo0r_e0cCCqhskoQvohXG3bfDAo8rIdE-Msu3yuVfyF2oiDFKHFOU-vxVulAfe8kPL7riFwoXa1bsfN-szjxO_8qUQWbPsJOnTg0EkutIoK2S4NNLL24JQh9e4DsE9hv907k2_zDbvj0a8WAj5oPSV5J0YhhGG6-fQ7-XNLWPcM_k3oTDL1NuljPlnkIp321u5A-xiH1gnzdnKNUDaWDA05lNtulswAaOAFzU2GVCfOHGjz2_N_qpZ6fC1QDq49BBQ_3gocPRM2SpoBrmMUFZcpiquyG17Wd7nLodpyYMrClfuyTbh5-Bw4IscSnvQo4tQ8flWLR8n29ZPcmVH4Wv2xd6-dQky0mNnl3r7Nqp2GqQPpItI-IDbUpYsXb7ayqDDNpKRBZZjcxN7l53xrHYO3XqJBdjW5rDMBDL4Z4bjBQUhNP4Md63Kr0Ked6GjEmWbph4wQ==&p=0&fvj=0&vjs=3	Myticas Consulting	BHJOB15656_15145 - Data Engineer w/ DevOps - Azure Cloud	2020-08-16T23:43:30.000Z	a32b7c599156a218	Toronto, ON	The growing team here at Myticas is looking for an experienced Data Engineer who would be interested in a remote contract opportunity within the Ottawa, Toronto and Montreal regions.

Accountabilities:

Defining and reviewing security design requirements for cloud infrastructure and application components.
Evaluating architecture patterns from security perspective.
Building and implementing security controls to enable enforcement of compliance with Cloud Control Objectives, using custom Azure policies and integrated controls in DevOps processes

Requirements:

Strong Data Engineer w/ DevOps expertise + Azure Cloud Experience
Must know how to code and stand up scripts.
Experience with Data Digestions
Experience writing scripts to automate (infrastructure)
ARM Templating Expertise
Azure Synapse Expertise
Support developing automated DevOps processes and procedures for the following Azure components:
Azure Synapse (Azure DW) & Studio (private preview)
Azure Data Catalog Gen 2 (Babylon – private preview)
Azure Data Lake Storage Gen 2
Azure ML
ML Flow
Azure SQL Analysis Service
Azure Databricks
ADF data pipelines for data loading to AzSQL/Synapse
ADF data pipelines for connecting to on-prem data sources for data

Candidates looking to apply for this role are to send us an updated version of their resume in confidence. Our team will be sure to review all applicants and follow up accordingly at the conclusion of the review process.

Job is also known as: Data Engineer, DevOps Engineer, Azure Cloud Engineer, Azure Engineer, Cloud Engineer

INDMY
202008162	2020-08-16T23:43:31.000Z	North York, ON	https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Dkh866153otbRJ8nVMuEXnXPd315JS377__3VyD6HnNQkmcaOHMemmy5pLrNV6j0WaVWEWWabnp4PP6-2u77DLfT_FCIGvCW8CQmQW140Z7EVU32Jnwl42FALsxnbc4n5M6FOTfoW2OoTMOcGG21HZGOoXL7fWT8eaT67VlcClh4sHQcJsHCX__M4wkdc4Gu-GdTWJeXL4LC0izAsAsUaihGRoShYdD1YRnjdpgwAeTmk1g-idogTirLBeALn2hclcLZr4z4DzY56BXgxSXXx1BKpzQxM9Q568E17O1Jy_AuTAG5Jz5kDdlVLLoZTWuMUPraMSK4mCngQCxTbdLny4UlHn2SeX_exaEx915tFJciV8O8BkVHpmDjWFnsTT-9bnB9bFxuXO1YbGUMHaSYF0WetYlNS5rwIcGoF-utk3idQdTOqMKJJvzENnSirp91Phf9Xedm2d2HxC92R-4w7ztI8mKjXwjkJp-J7pu627iidQTeKRXP1E&p=1&fvj=1&vjs=3	997673b8effa647f	Data Engineer (Intermediate 4-6 years) - Contract - Remote during COVID	CorGTA	Role: Data Engineer (Intermediate 4-6 years)Structure: Contract (6 months initially)Location: North York, ONHours: Monday - Friday 40 hours (remote during COVID-19)Pay: $50.00 p/h inc.The role: We are looking for Intermediate Data Engineers who have roughly between 4-6 years experience who ideally has experience moving data from Google cloud over to Big query.However, if you are someone who has good experience with ETL and Data Pipeline Design & Data Validation experience and can script in Python and create strong SQL Queries then this will also be a potential match for this role.Ideal Qualifications to be successful in this role: - Degree in Computer Science, Engineering, Information Systems (or equivalent combination of skill and experience)- 4-6 years of experience working with data architecture projects- Excellent SQL coding and experience with a broad array of development tools and platforms including exposure to a big data environment tools/languages, such as SQL, R, SAS, Python, etc.- Experience creating relational database design and data models- Experience with various analytical data platforms and technologies- Experience with using REST API, Cloud (GCP Ideally)- Experience in custom or structured data integration design, implementation, and maintenance- Experience with business intelligence tools such as Qlikview, Tableau and Microstrategy (Nice to have for Data Visualizations)- Previous experience working in retail or eCommerce is highly preferred- Ability to curate data to tell stories and provide business insightsPlease apply with an updated resume and ensure the required skills you are able to speak to for this position are included.For more roles like this please go to www.corgta.com/find-a-job/Job Type: Full-timeSalary: $45.00-$50.00 per hour
202008163	If you are looking to join one of Canada’s fastest growing companies, goeasy Ltd. is the place for you! Recognized as one of Canada’s Most Admired Corporate Cultures, one of Canada’s Top 50 Fintech’s and one of North America’s Most Engaged Workplaces, we want the best and brightest to join our team.

We are a publicly traded company on the TSX with over 4000% shareholder return since 2001, goeasy operates two main business units. easyfinancial is our consumer lending business that offers secured and unsecured installment loans of up to $35,000 and easyhome is Canada’s largest merchandise lease-to-own company. It is our mission to provide everyday Canadians the chance for a better tomorrow, today by giving them access to the credit they need and by offering them a second chance when they have been turned down by banks and traditional lenders. With a retail network of nearly 400 locations across Canada and over 1900 employees, we are able to build lasting relationships with our customers as we help them rebuild their credit and graduate towards prime rates and a brighter financial future.

The Data Engineer on the Data Science and Business Insights team will build, integrate data from various resources, manage data in goeasy operational data store and enterprise data warehouse. This position will develop ETL (Extract, Transform and Load) with various tools on large datasets to ensure data is easily accessible, works smoothly, as well as maintain and expand the data warehouse for reporting and analysis. The Data Engineer will also work closely with the data architect on the design and architecture of our enterprise data warehouse.

Responsibilities:

Develop data set processes for data modeling, mining and production
Develop and maintain ETL processes using SSIS, Scripting and data replication technologies
Participate in development of datamarts for reports and data visualization solutions
Research opportunities for data acquisition and new uses for existing data
Integrate new data management technologies and software engineering tools into existing structures
Support the translation of business requirements for data acquisition/manipulation and provide detailed specifications that can be passed downstream for use
Develop detailed technical specifications and operational support documentation in collaboration with Business Systems Analysts, BI Engineers and Architects.
Identify and communicate technical problems, process and solutions
Create Ad-Hoc queries and reports as needed along with providing on-going analytical support for these requests
Assist in the collection and documentation of user’s requirements
Ensure that existing business processes dependent on the ODS/EDW are monitored and respond quickly to bug fixes, enhancement requests and production ETL related issues.
Dealing with the database users on a daily basis to ensure that problems are dealt with promptly and that appropriate fixes are made to resolve any problems.
Recommend ways to improve data reliability, efficiency and quality
Ensure systems meet business requirements and industry practices
Work effectively with the Business Intelligence and Data Solutions Architects, Data and BI Engineers to ensure that all approved development and deployment procedures are followed.

Qualifications:

Bachelor’s Degree in Computer Science, MIS, Computer Engineering or other Information Technology related degree
4+ years working with SQL Server or comparable relational database system
3+ years of extensive ETL development experience with SSIS and/or ADF
4+ years of experience troubleshooting within a Data Warehouse environment
Expert domain knowledge & experience in Data warehousing, encompassing data model design, dimensional modeling, naming conventions, cross-cutting concerns, common integration technologies, patterns & standards and emerging technologies.
Expert Knowledge of SQL skills to build, debug, and optimize (developing procedures, functions, SQL queries, etc.) and working with large data sets and to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
2+ years SQL Server Database administration experience
Cloud experience (Azure) is highly preferred
Exposure and experience with Python, R, Hadoop, Azure, other Big data and advanced analytics
Knowledge of AI and ML developments/solutions/implementations
Experience with multiple programming languages (PowerShell scripting, C#, others) with basic scripting skills.
High level of technical aptitude

Inclusion and Equal Opportunity Employment

goeasy is an equal opportunity employer. In addition, goeasy is committed to providing accommodations for applicants upon request at any stage of the recruitment process in accordance with all legislative requirements throughout Canada. Please let us know if you require an accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.

Additional Information:

All candidates considered for hire must successfully pass a criminal background check, credit check, and validation of their work experience to qualify for hire. We thank all interested applicants, however we will only be contacting those for interview who possess the skills and qualifications outlined above.

Why should you work for goeasy?

To learn more about our great company please click the links below:

PAID1234	Mississauga, ON	2020-08-16T23:43:32.000Z	Data Engineer	e8f01b72a171ac29	goeasy	https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DbNJQGwjC-NEA80-qlVyEGmSv34Xx0eW4t4u9rXSv_7_tlvMU2e-Gw_wrZ47s1zPCnrySU2yuEL07wtSyx7XOwYh5VPcVL7CxRhOYwHzR-CdmyBrwbeqommOn6y9FD_uKIYpUCb9-PC_XgwGzBDrPy7SD7JQndrQeehFId1t3SaRITV0cXFzu_SmJXsQbDJ0uWZ5tmhgYdEXmXpGJ5Fap-USlNGZsyMbwLtMbbXeb1ZrMTYzQjcQMQUhDaqRVABHn4Tc0c6B4ueDcUnV-fLEbULXFbhR_wfM3gvwEy79CbVz8WyRHN43b6nTxeIll2hX-uOkMWIk44dczwkEJlvDvL2YpExo-x8k5wM-slkLpy_8JCOpEsRyyUIRYXPcjI0LemgfHQPCCOLA7Oafr7Nk0ID7_ZbJvI9TK7aFtJ8X4dp2E_QAzeKdSKUlg4ucJxOAPQjf1-wHAs8hiD8YjirmsM58GU_GvEcprCTNj7in6dzA==&p=2&fvj=0&vjs=3
202008164	https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DQQnUBuQBSuyaIQhpC59TW7hrTbBg8v-nGtzzV8dunbQHh9VTp-k89gJ8q3B9UEXLHcYbAG67d8jpOK4E3ok8olcOhfyyiChWMI3BPvUFdra3ljwgLS_vFsJXlW6jHt2NpQMzd2p9F6BXGm9ND3feUN42yGy4tVXA7pjnlOB1H9LvEd49dcuuLk4svzjAl8xs98YeEJKd7Q-aNEX4qj8wG4pdOJssnjw6h1BSQJzknqQcCivd_35g1_dsInC0MI93t1V6X9a3iGvf8aCIbLhCfi0-_wQlgfaHUOYb0ClspzWTDW1DaOn-baitEWnr6mWSxu4ZKjyp6OhTULp8um8rTLcdAHClWXkUY8xXTs4qWbo8CeXlB9hXvWBC_pgfEo5d0Mk1KEuZ8CAJknJb-TMAmNZoaktTrT88lNmaVLpKgpIBQx1Bbdw3aJ5LyYLi-MqEhZF3PQxQcQrlgsJ7BbcNKbfp6MBHUz0r9kriCw0BW1wcWDLvtZU77_Eu-58mT9V9RrK7QrtvBK-SOlUdNRTLY5KEUsHK5eMPNQJFkisGKsyH0lNxiI4SDOb_JuR4BUCs52Bs3zZGkjj3lUAlhXBoJaK65AtDQJkdlGjsnowP3jKRFNisZk_FA8fLwr-4-BKrskGVpTdqv8Qdz3E1xxqlNYaKkVudVLczYIXJ8_cSlWccXczFypFLPrPzo9io1x6WGk6ar2wWykuuhBm4MRXclEcD_a5t94C2U99w0bcQsvfL8Zzy2kobcW8b1zr124svmx8qPQJtxerql3QZz-VYCf-lB1xJlCKKEg0_OVKfyx5lGqh8VlgTH8oR93fA7vIdJfprOKdg8YyjVNShiv3c3&p=3&fvj=0&vjs=3	2020-08-16T23:43:33.000Z	Job Title- Data Engineer
Location- Downtown, Toronto
Type - Full Time Permanent
Salary - Negotiable + Benefits



Focus on data architecture, best practices, reliability, security, and complianceImprove and extend ETL, data processing, and analytics processesFacility with PowerBI, including creating dashboards and data sourcesDeveloping high complexity, fast performing SELECT queries.Developing T-SQL procedures, functions, triggers, jobs, scripts, etc.Development of Advanced T-SQL such as temporal tables, PIVOTs, recursive table expressions and more.Modeling and implementing Data Mart solution for Power BI analytics
Managing indexes, statistics, query plans alerts, database activity, and overall performance activity.In-depth experience working with relational databases, such as Microsoft SQL Server or PostgreSQLEnthusiasm for applying good data design, testing, documentation, and support practicesExperience building and optimizing data pipelines, architectures, and data setsKnowledge of message queueing, stream processing, and data stores/warehousesWorking knowledge of AWS products related to data engineeringBachelor's degree in Computer Science, Software Engineering or an equivalent
Excellent communication skills - both written and verbal; ability to speak in Spanish is a bonus

To apply please send an email to sheetalk@tes.net	Data Engineer	Toronto, ON	TES - The Employment Solution	05f7bf2a7458c7fc
202008165	fbcc383eeed7b6dc	Data Engineer	There is never a typical day at Accenture, but that’s why we love it here! This is an extraordinary chance to begin a rewarding career at Accenture Technology. Immersed in a digitally compassionate and innovation-led environment, here is where you can help top clients shift to the New using leading-edge technologies on the most ground-breaking projects imaginable.

Interested in building end-to-end marketing solutions for clients? Bring your talent and join Data which operates in the Interactive, Mobility and Analytics space. You will have opportunities to get involved in digital marketing, eCommerce and end-to-end mobility capabilities to help clients to improve productivity and more!

WORK YOU’LL DO
Work across the Service Delivery Lifecycle to analyze, design, build, test, implement and/or maintain multiple system components or applications for Accenture or our clients
Responsible for the maintenance, improvement, cleaning, and manipulation of data in the business’s operational and analytics databases
Support our database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects
Determines methods and procedures on new assignments with guidance
Manages small teams and/or work efforts (if in an individual contributor role) at a client or within Accenture

WHO WE´RE LOOKING FOR?
Minimum 5 years of experience as a Data Engineer
Must have experience with one of the Cloud Technologies (Azure or AWS)
Azure cloud includes Spark, Python, Databricks, Synapse, Snowflake, Data Factory and ADLS
AWS cloud includes Glue, EC2, EMR, Athena, redshift, Snowflake, S3, Spark, Python and Databricks
Experience with Big Data technologies like MapReduce, Pig, Hive, HBase, Sqoop, Flume, YARN, Kafka, Storm and etc.
2+ years of experience with at least one SQL language such as T-SQL or PL/SQL
2+ years of work experience with ETL and data modeling
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets
Experience in both batch and stream processing technologies
Experience with object-oriented/object function scripting languages: Java, C++, Scala
Machine learning experience with Spark or similar
Professional Skills Qualifications:
Proven success in contributing to a team-oriented environment.
Proven ability to work creatively in a problem-solving environment.
Desire to work in an information systems environment.
Demonstrated teamwork and collaboration in professional setting; either military or civilian.
WHAT´S IN IT FOR YOU?
Competitive benefits, including a fair and balanced parental leave policy.
Fantastic opportunities to develop your career across industries with local and global clients.
Performance achievement and career mentorship: our performance management process focuses on your strengths, progress and career possibilities.
Opportunities to get involved in corporate citizenship initiatives, from volunteering to charity work.
To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.
It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve our clients, our employees must be available to travel when needed.

Accenture does not discriminate on the basis of race, religion, color, sex, age, non-disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. Accenture is committed to providing employment opportunities to current or former members of the armed forces.

We are committed to employment equity. We encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply.

Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 469,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com	Toronto, ON	2020-08-16T23:43:34.000Z	https://ca.indeed.com/rc/clk?jk=fbcc383eeed7b6dc&fccid=a4e4e2eaf26690c9&vjs=3	Accenture
202008166	Title: Data EngineerLocation: Toronto, CADuration: 6+ monthsExpertise in the design, creation, management, and business use of large datasets, across AWS Data and Analytics product.Excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build the required data pipelines.Crafting, implementing, and operating stable, scalable, low cost solutions data pipelines to ingest real-time and event-based data using AWS technologies.5+ years of work experience with Data Pipelines, Data Modelling, and Data Architecture. ·Expert-level skills in writing and optimizing SQL.Proficiency in python scripting languages and integrating it with lambda-based processing in AWSExperience operating very large data warehouses or data lakes.Experience with building data pipelines and applications to stream and process datasets at low latencies. ·Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data. ·Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines using KinesisGood understanding of different DB technologies like Dynamo DB (NoSQL),Aurora DB ( RDBMS), Redshift (In-Memory DBs), across AWS stack.Job Types: Full-time, ContractSalary: $70.00-$75.00 per hourExperience:AWS: 1 year (Preferred)Work remotely:Temporarily due to COVID-19	2020-08-16T23:43:35.000Z	904ae8a46b296ad2	Data Engineer	Toronto, ON	https://ca.indeed.com/company/NLB-Services-Inc/jobs/Data-Engineer-904ae8a46b296ad2?fccid=0b209b5526418580&vjs=3	NLB Services Inc
202008167	2020-08-16T23:43:36.000Z	6e7b18ed4b257445	https://ca.indeed.com/rc/clk?jk=6e7b18ed4b257445&fccid=e981b35e4c0452a3&vjs=3	CI Investments Inc	Data Engineer	ABOUT US
CI Investments Inc. is one of the country’s largest investment fund companies. CI is known for its innovation and ability to adapt quickly to the changing needs of Canadian investors. It provides employees with a fast-paced and challenging work environment with opportunities for advancement. CI is part of CI Financial, a diverse group of financial services firms.
POSITION: Data Engineer
LOCATION: Toronto (M5J 0A3)
STATUS: Contract (6 months with extension possibility)
JOB OVERVIEW
We are currently seeking a Data Engineer to join our Client Reporting and Data Management team. The successful candidate will work closely with our data science team on the development of our centralized predictive analytics function. In this role, you will assist with solving high-value business problems by extracting and manipulating large, complex datasets for use by data scientists. The role will be a six-month contract position, with an option to extend based on performance.
WHAT YOU WILL DO
Collaborate with business analysts, data scientists, software engineers, and solution architects to develop data pipelines to feed our data marketplace
Extract, analyze & interpret large, complex datasets for use in predictive modelling
Utilize AWS tools to develop automated, productionized data pipelines
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Develop and support ETL code for data warehouse and data marts to support the reporting and data analytic systems.
WHAT YOU WILL BRING
At least two years of work experience in quantitative analysis
Post-secondary degree in a quantitative discipline
Experience with large-scale, AWS big data storage such as S3 and EBS
Experience creating ETL jobs using AWS Glue or Talend
Experience with AWS Data pipeline tools like Cloudwatch and Stepfunctions
Experience working with data preparation tools like Talend
Experience in the Financial Services Industry is an asset
Strong knowledge with programming methodologies (version control, testing, QA) and agile development methodologies.
In-depth knowledge of AWS tools required to develop automated, productionized data pipelines
In depth knowledge of and experience with relational, SQL and NoSQL databases
Fluency with SQL and Python
Experience working with large, complex datasets
Excellent communication, writing and interpersonal skills
WHAT YOU CAN EXPECT FROM US
Our dedication to the Employee Experience at CI is aimed at supporting, empowering and inspiring our talented team through:
Recognition & Compensation
Training & Development
Health & Well-being
Communication & Feedback
If you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking “Apply”.
Only qualified candidates selected for an interview will be contacted.
CI Financial Corp. and all of our affiliates (“CI”) are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. If you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at accessible.recruitment@ci.com, or call 416-364-1145 ext. 4747. If you are contacted by CI regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. We will work with all applicants to determine appropriate accommodation for individual accessibility needs.	Toronto, ON
202008168	2020-08-16T23:43:37.000Z	3+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQL

Amazon.com was recently voted #2 most admired company in the US, #1 most innovative, and # 1 in Customer Service. We are investing heavily in building an excellent advertising business, and are responsible for defining, and delivering a collection of self-service performance advertising products – “always-on analytics” that is fully scalable and reliable. Our products are strategically important to our leadership, finance, economists, analysts, and BI partners to drive long-term growth. We mine billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative, and fun loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.
The Advertising Analytics and Data Management team is looking for an exceptional Data Engineer who is passionate about data and the insights that large amounts of data can provide, who thinks/acts globally, and who has the ability to contribute to major novel innovations in the industry. The role will focus on working with a team of data engineers, business and tech savvy professionals to lay down scalable data architecture to ingest large amounts of structured and unstructured datasets and work with stakeholders to drive business decisions based on these datasets.

The ideal candidate will possess both a data engineering background and a strong business acumen that enables him/her to think strategically and add value to the customer experience. He/She will experience a wide range of problem solving situations, requiring extensive use of data collection and analysis techniques such as data mining and machine learning.

The successful candidate will work with multiple global site leaders, Business Analysts, Software Developers, Database Engineers, Product Management in addition to stakeholders in sales, finance, marketing and service teams to create a coherent customer view. They will:

Develop and improve the current data architecture using AWS Redshift, AWS S3, AWS Aurora (Postgres) and Hadoop/EMR.Improve upon the data ingestion models, ETL jobs, and alarming to maintain data integrity and data availability.Stay up-to-date with advances in data persistence and big data technologies and run pilots to design the data architecture to scale with the increased data sets of advertiser experience.Partner with analysts across teams such as product management, operations, sales, finance, marketing and engineering to build and verify hypothesis to improve the business performance.Manage weekly business reports via dashboards and paper the analyses of daily, weekly, and monthly reporting of performance via Key Performance Indicators.

AWS ExperienceAdvertising domain knowledge is a plus
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

#sspajobs	AMZN CAN Fulfillment Svcs, ULC	59c48782b60cacd0	https://ca.indeed.com/rc/clk?jk=59c48782b60cacd0&fccid=fe2d21eef233e94a&vjs=3	Data Engineer	Toronto, ON
202008169	Fluid Hose & Coupling	https://ca.indeed.com/company/FLUID-HOSE-&-COUPLING-INC/jobs/Junior-Data-Engineer-7cc1b932ac3ee1bf?fccid=5156f9b5283a3233&vjs=3	Mississauga, ON	Job summaryResponsible for the completion of long-term IT engineering projects. Performs engineering design evaluations and works to complete projects within budget and scheduling restraints. Develops, implements, and monitors information systems policies and controls to ensure data accuracy, security, and regulatory compliance.Responsibilities· Responsible for the analysis, improvement, cleaning, and manipulation of legacy relational databases at the company.· Responsible for the architectural design and development of a modernized database, integrated with legacy systems.· Responsible for the full-stack development of web applications which enhance customer and employee relationships with company data.· Responsible for general development and maintenance of the company's IT systems, including web server maintenance and website updates.· Works with the business’s leadership team, in order to aid in the implementation of database requirements and troubleshoot any existent issues.· Defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.· Manages Salesforce database base as required by sales leadershipEducation and Skill Requirement· Computer Programming degree or equivalent. Equivalence may be demonstrated from past projects, results, etc· Computer Programming/Cloud Computing/Data Science/Data Engineer/Database Management/IT Security and Infrastructure· Ability to learn new technologies unguided/with minimal intervention (Adaptability)· Complete knowledge of Web programming, design, e-commerce, SQL and relational DB Design. Understands data structures and hierarchies (1-2+ years of experience with SQL, or any other database management system)· Clear understanding of System Architecture and ERP systems· Detail oriented, organized with strong analytical and critical thinking skills· Excellent communication skills combined with patience in the process· Excellent Excel and MS Office skills with a deep understanding of Excel macros and programming. May be required to demonstrate this in a remote interview by example· Quick learner and familiar with CRUD Operations· Resourcefulness to keep moving forward (does not stall at a challenge)· Preference will be given to those who understand App design and machine learningJob Types: Full-time, PermanentSalary: $40,000.00-$40,001.00 per yearBenefits:Dental CareExtended Health CareOn-site ParkingSchedule:8 Hour ShiftMonday to FridayEducation:Bachelor's Degree (Required)Work remotely:No	7cc1b932ac3ee1bf	2020-08-16T23:43:38.000Z	Junior Data Engineer
2020081610	https://ca.indeed.com/company/ARISOFT-INC./jobs/Data-Engineer-76d86fb24f1bdc31?fccid=1dbce7609f8e0b52&vjs=3	ARISOFT INC.	Data Engineer - Datamart Azure	2020-08-16T23:43:39.000Z	76d86fb24f1bdc31	Toronto, ON	Data EngineerRequirements: · 8+ years of hands-on development experience in multiple projects, with progressively increasing responsibility and ETL background, and an understanding of type 2 dimension, and prior experience with data marts.· 5+ years of hands-on experience working with data warehousing like applications and big data.· Experience leveraging big data technologies (One or more of Hadoop, Python, Spark) is required.· Exposure to Microsoft Azure (or other cloud) platforms is preferred· Experience working with various data exchange formats (JSON, CSV, XML etc.)· Solid understanding of relational and dimensional database design and knowledge of logical and physical data models is preferred· Experience with SDLC and/or Agile methodologies for project development, and participation in all phases of project development, is required· Excellent knowledge of SQL and Linux shell scripting· Experience in deploying and managing SQL and NoSQL databases is preferred· Experience with job scheduling (TIDAL, CAWLA, Oozie) and file transfer (e.g. SFTP)· Excellent diagnostic, analytical and problem-solving skills are preferred· Experience with continuous delivery tools (Jenkins, Bamboo, Circle CI), and an understanding of the principles and pragmatics for build pipelines, artefact repositories, zero-downtime deployment, etc. is preferred· Experience building real-time data pipelines using Kafka or spark streaming is preferredKey Accountabilities: · Perform technical systems and data flow development in a variety of projects for complex front, middle and back office applications, with a focus on the reporting and analytics environment; this environment is built on a Microsoft Azure cloud and is underpinned by a Hortonworks Hadoop stack· Perform technical systems and data flow design for small-to-medium sized projects· Work with multiple project execution and deployment teams (e.g. Development Architecture, Release Management, Production Support)· Work closely with source system SMEs to produce source to target mappings· Translate business requirements to technical specifications· Work closely with the technical leads and architecture teams, and align solutions that meet the departmental architectural vision· Able to handle multiple priorities seamlesslyJob Types: Full-time, ContractSalary: $89,471.00-$170,126.00 per yearExperience:total IT: 10 years (Required)dartmart: 2 years (Required)Data engineer: 10 years (Required)Azure: 3 years (Required)Big data: 3 years (Required)ETL: 5 years (Required)Work remotely:Temporarily due to COVID-19
2020081611	Vector Institute	Data Engineer, GEMINI (Contract)	2020-08-16T23:43:40.000Z	25f6a9d8e47d869e	https://ca.indeed.com/rc/clk?jk=25f6a9d8e47d869e&fccid=1a9a6d236cf89e9e&vjs=3	POSITION OVERVIEW


The Vector Institute is seeking a Data Engineer, GEMINI to join our team in Toronto. This role will predominantly work with the General Medicine Inpatient Initiative (GEMINI) team at St. Michael’s Hospital, in addition to providing support to the Vector community.


The Data Engineer, GEMINI will primarily work in R to lead a team to automate and optimize GEMINI’s data pipeline workflow including extracting, transforming and loading data, conducting quality and validation checks, and standardizing data from multiple data sources. The ideal candidate will have excellent programming skills, a strong understanding of data pipelines and analytic methods, an aptitude for data visualization, and strong leadership and communication skills. You will be joining a dynamic and mission-driven team of clinicians, scientists, and quality improvement experts.
EMPLOYMENT TYPE


Contract (18 months)


ABOUT THE VECTOR INSTITUTE


A thriving, independent not-for-profit, the Vector Institute strives to advance the Artificial Intelligence ecosystem in Ontario, developing and attracting the world’s best machine learning and deep learning experts, and creating an unrivalled convergence of research, investment, entrepreneurialism, and economic growth. Located in the MaRS Discovery District in downtown Toronto, we are part of a dynamic and vibrant community of research, academia, health science and commerce.


ABOUT GEMINI


Co-led by Drs. Fahad Razak and Amol Verma, GEMINI has developed methods to extract and standardize data from electronic health records to harness the tremendous potential of data generated through routine patient care of General Internal Medicine hospital inpatients for research and quality improvement purposes. GEMINI is a unique data platform in the Canadian healthcare landscape and currently exists at 7 hospitals, with data collected on 345,000+ patient visits, including billions of data points. The GEMINI data platform has recently been funded to expand to the 30 largest hospitals in Ontario to support data analytics that inform the COVID-19 pandemic response. GEMINI supports a network of nearly 100 collaborating scientists and more than 40 students, including clinicians, computer scientists, biostatisticians, epidemiologists, social scientists, and engineers.
RESPONSIBILITIES


Develop scripts to extract, transform and load data from multiple data sources into GEMINI’s platform;

Gather requirements and conduct analyses to design, develop and maintain secure data pipelines;
Automate and optimize GEMINI’s data pipeline workflows;
Provide leadership and guidance to data pipeline team;
Maintain and update on-going quality assurance of data workflows;
Engages with team and collaborators to understand needs and requirements;
Documents data pipeline architecture;
Routinely tests and monitors system for failures, errors, breaches;
Troubleshoot problems;
Provides teaching and training as needed;
Create and update Standard Operating Procedures and other documentation files, as needed;
Establish methods to improve and automate data workflow of rapidly changing COVID-19-related data;
Support GEMINI’s data platform as required; and,
Perform other functions as required (e.g., providing scientific advice and support to other members Vector’s teams and corporate projects led by Vector).


SUCCESS MEASURES


GEMINI’s data pipeline workflow is automated and optimized through the development of algorithms and procedures.
High quality coding practices are maintained.
Significant contributions are made towards GEMINI’s data platform.


PROFILE OF IDEAL CANDIDATE


A degree in Engineering, Computer Science and/or related discipline; graduate degree preferred
At least 5 years’ relevant professional experience
Fully knowledgeable in designing and testing of data pipelines required
Extensive experience in SQL as well as at least one of either R or Python required
Familiarity of key databases such as: PostgreSQL, MySQL, Oracle, etc. is preferred
Knowledge of Linux commands and Shell scripts required
Strong analytical, technical design and problem-solving skills required
Strong working knowledge of Microsoft Office products (e.g. Outlook, Word, Excel, PowerPoint) required
Experience with GitHub preferred
Good judgement and understanding of what issues to escalate, resolve on your own, making suggestions for possible resolution required
Ability to learn new technology expediently required
Demonstrated success working within interdisciplinary teams
Experience with the Ontario healthcare system is an asset
Excellent attention to detail and proven ability to learn new skills
Experience working independently and as part of a team
Excellent organizational skills to manage multiple tasks in a timely manner
Demonstrated flexibility and have the ability to adapt and manage changing priorities


Please address applications (cover letter and resume) to Kailyn Burke, HR Generalist, using the link provided. Review of applications will begin August 19, 2020. We thank all applicants for their interest in this exciting opportunity and will be in touch with those whose qualifications most closely match with our needs. Please note that candidates may be required to demonstrate proficiency in R.

The Vector Institute is committed to employment equity and diversity in the workplace and welcomes applications from women, racialized persons/visible minorities, Indigenous peoples, persons with disabilities, and LGBTQ+ persons. All qualified candidates are encouraged to apply.


Further, we are committed to fostering an environment of inclusivity and accessibility. If you require an accommodation at any point throughout the recruitment and selection process, please

contact hr@vectorinstitute.ai and we will happily work with you to meet your needs.	Toronto, ON
2020081612	https://ca.indeed.com/company/SDK/jobs/Data-Engineer-1e5daca6232e90a6?fccid=185dce58b577e4a6&vjs=3	2020-08-16T23:43:41.000Z	1e5daca6232e90a6	Data Engineer	SDK	Toronto, ON	Job DescriptionSDK is looking for Big Data Engineers that will work on the collecting, storing, processing, and analyzing of huge sets of data. The Data Engineer must also have exceptional analytical skills, showing fluency in the use of tools such as MySQL and strong Python, Shell, Java, PHP, and T-SQL programming skills. He must also be technologically adept, demonstrating strong computer skills. The candidate must additionally be capable of developing databases using SSIS packages, T-SQL, MSSQL, and MySQL scripts.The candidate will also have an ability to design, build, and maintain the business’s ETL pipeline and data warehouse. The candidate will also demonstrate expertise in data modeling and query performance tuning on SQL Server, MySQL, Redshift, Postgres or similar platforms.Experience:ETL: 5 years (Preferred)Software Development: 5 years (Preferred)Data Integration: 5 year (Preferred)Spark Programming (Azure Databricks preferable)Python, Java & SQLKnowledge of Azure Cloud (Data Platform Technologies)Experience and commitment to development and testing best practices.Manage high volume, high traffic GDPR solutions buildSCALA a nice to haveSDK is looking for Big Data Engineers that will work on the collecting, storing, processing, and analyzing of huge sets of data. The Data Engineer must also have exceptional analytical skills, showing fluency in the use of tools such as MySQL and strong Python, Shell, Java, PHP, and T-SQL programming skills. He must also be technologically adept, demonstrating strong computer skills. The candidate must additionally be capable of developing databases using SSIS packages, T-SQL, MSSQL, and MySQL scripts.The candidate will also have an ability to design, build, and maintain the business’s ETL pipeline and data warehouse. The candidate will also demonstrate expertise in data modeling and query performance tuning on SQL Server, MySQL, Redshift, Postgres or similar platforms.Base Qualifications3+ years of demonstrated data engineering experience or development experience3+ years of experience with Big Data Technologies like Hadoop or Hive3+ years' experience in custom ETL design, implementation and maintenanceProficient designing and implementing data models and data integrationExperienced deploying Azure SQL Database, Azure Data Factory and well-acquainted with other Azure services including Azure Data Lake and Azure MLExperience implementing REST API calls and authenticationExperienced working with agile project management methodologiesPreferred QualificationsAt SDK we believe “perfection” is a process. We hire for fit and invest in training, so our people continue to be the best for themselves, SDK, and SDK's customers.EducationComputer Science Degree/DiplomaMicrosoft Certified: Azure Data Engineer Associate:Job Types: Looking for full-time employees only. No Contractors. Must be eligible to work in Canada.Job Types: Full-time, ContractExperience:Data Engineering: 5 years (Preferred)Location:Toronto (Required)Work remotely:Temporarily due to COVID-19
2020081613	2020-08-16T23:43:42.000Z	Toronto, ON	What is the Opportunity?

The DNA (Data & Analytics) group is responsible for enabling RBC to become a data-driven organization. As part of this mission, DNA works with various lines of business (Personal & Commercial Banking, Wealth Management, Insurance, Capital Markets, etc…) to create and build data-driven solutions to serve our clients better. You will be part of a strong team of developers building out our reusable, core data services to deliver value to business partners through data, insights and AI.
The DNA Data Services team will build data-driven products and services/API’s, tackle challenging and interesting data-related problems using RBC's massive internal datasets (client relationships, user behavior across channels, transactions, etc….) and strategically partner with the business to enable client interactions to be informed by Artificial Intelligence (AI).

What will you do?

 Build large-scale real-time data pipelines using the latest technologies.
 Apply design thinking and an agile mindset in working with other engineers, data scientists and business stakeholders to continuously experiment, iterate and deliver on new initiatives.
 Leverage best practices in continuous integration and delivery.
 Help drive transformation by continuously looking for ways to automate existing processes and testing and optimize data quality.
 Explore new capabilities and technologies to drive innovation

What do you need to succeed?

Must-have
 Bachelor’s degree in computer science, software engineering, or equivalent
 5+ years development experience in Java
 2+ years’ experience with streaming or messaging technologies (Kafka, etc…)
 2+ years’ experience in Big Data environments (Spark, Hadoop, etc…)
 Experience building operational REST APIs
 Strong foundational knowledge of relational databases (MySQL, SQL Server, etc…) and NoSQL stores (Elasticsearch, Neo4j, MongoDB, etc…)

Nice-to-have
Knowledge of public cloud environments (AWS, Azure)
 A passion for simplifying and automating work, making things better, continuous learning, solving open-ended problems, improving efficiency and helping others

What’s in it for you?

 We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.
A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Ability to make a difference and lasting impact
Work in a dynamic, collaborative, progressive, and high-performing team
A world-class training program in financial services
Flexible work/life balance options
Opportunities to do challenging work
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with clients
Access to a variety of job opportunities across business and geographies	Senior Data Engineer	https://ca.indeed.com/rc/clk?jk=55e49e6c1c9af157&fccid=537b899e30af3338&vjs=3	RBC	55e49e6c1c9af157
2020081614	2020-08-16T23:43:43.000Z	https://ca.indeed.com/company/Smarttechlink-technologies/jobs/Aws-Data-Engineer-91168fc331947e74?fccid=7be406286ca6842e&vjs=3	AWS Data Engineer	Job Description: AWS Data engineer with 3-5 years work experience using Python, PySpark, AWS EMR and Airflow. The desired candidate should have strong development skills and experience on datalake implementation including data extraction and building data pipeline.Job Type: Full-timePay: $94,832.00-$120,000.00 per yearSchedule:Monday to FridayExperience:AWS Data: 3 years (Preferred)	91168fc331947e74	Toronto, ON	SmartTechlink Sollutions Inc.
2020081615	2020-08-16T23:43:44.000Z	Must have:
Strong Spark, Kafka and are familiar with Flink/Druid/Ignite/Presto/Athena

You are proficient in Java/Scala/Python/Spark	5929006533b711f6	https://ca.indeed.com/rc/clk?jk=5929006533b711f6&fccid=580f6b9a5ada66c2&vjs=3	Data Engineer- Permanent, downtown Toronto	Toronto, ON	IT Connex